feat: implement Phase 3 translation service infrastructure with caching and background processing

Completed Phase 3 of the multilingual content system by implementing a comprehensive translation infrastructure:
- Added TranslationCache class with SHA256-based key generation, 24-hour TTL, and thread-safe operations
- Enhanced TranslationService to integrate caching, reducing API calls and improving performance
- Implemented TranslationQueueManager with background processing, priority queuing, and exponential backoff retry logic
- Modified ConversationService to use asynchronous translation queue instead of blocking immediate translation
- Added database schema support for translation status tracking (pending, in_progress, completed, failed)
- Integrated OpenAI Prompts API for translation with robust error handling and validation
- Built concurrent queue processing with maximum 3 simultaneous translations and 30-second processing intervals

This creates a scalable, cost-effective translation system that processes translations in the background while providing immediate guidance
responses to users. Translation failures are handled gracefully with automatic retries, and the caching system significantly reduces API costs
for repeated content.
